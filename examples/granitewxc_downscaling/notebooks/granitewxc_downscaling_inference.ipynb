{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4548c3cc-7537-4d14-8d3e-c703e08098df",
      "metadata": {
        "id": "4548c3cc-7537-4d14-8d3e-c703e08098df"
      },
      "source": [
        "# Prithvi WxC Downscaling: Model Inference\n",
        "\n",
        "This notebook is a walk through to use a finetuned downscaling model to generate inferences. We show how to initalize the model, load weights, and use the model for inference"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install h5netcdf matplotlib wget pyyaml xarray scipy torch PrithviWxC granitewxc huggingface_hub"
      ],
      "metadata": {
        "id": "-RkKsdZLfDvP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb856c1e-a6ae-4b31-e5db-7c74e2cc42cf"
      },
      "id": "-RkKsdZLfDvP",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: h5netcdf in /usr/local/lib/python3.10/dist-packages (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (3.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (6.0.2)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.10/dist-packages (2024.11.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: PrithviWxC in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: granitewxc in /usr/local/lib/python3.10/dist-packages (0.1.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.27.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from h5netcdf) (3.12.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from h5netcdf) (24.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.10/dist-packages (from xarray) (2.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1->xarray) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1->xarray) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.12.14)\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "id": "caf141b3-6577-4846-9793-a1db11edbd2b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-09-20T19:57:48.680880Z",
          "iopub.status.busy": "2024-09-20T19:57:48.680564Z",
          "iopub.status.idle": "2024-09-20T19:57:48.740394Z",
          "shell.execute_reply": "2024-09-20T19:57:48.739891Z",
          "shell.execute_reply.started": "2024-09-20T19:57:48.680854Z"
        },
        "id": "caf141b3-6577-4846-9793-a1db11edbd2b"
      },
      "source": [
        "import os\n",
        "import wget\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import product\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "from granitewxc.utils.config import get_config\n",
        "from granitewxc.utils.data import _get_transforms\n",
        "from granitewxc.datasets.merra2 import Merra2DownscaleDataset\n",
        "from granitewxc.utils.downscaling_model import get_finetune_model\n",
        "from PrithviWxC.dataloaders.merra2 import SampleSpec\n",
        "from granitewxc.utils.plot import *"
      ],
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "id": "73c34161",
      "metadata": {
        "id": "73c34161"
      },
      "source": [
        "Configure the backends and torch states, including setting the seeds for the RNGs"
      ]
    },
    {
      "cell_type": "code",
      "id": "f6eaba0e-9a11-4c54-bb61-f9e5350dda09",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-09-20T18:30:34.397306Z",
          "iopub.status.busy": "2024-09-20T18:30:34.396814Z",
          "iopub.status.idle": "2024-09-20T18:30:34.817974Z",
          "shell.execute_reply": "2024-09-20T18:30:34.817220Z",
          "shell.execute_reply.started": "2024-09-20T18:30:34.397276Z"
        },
        "id": "f6eaba0e-9a11-4c54-bb61-f9e5350dda09",
        "ExecuteTime": {
          "end_time": "2024-12-12T11:06:08.455033Z",
          "start_time": "2024-12-12T11:06:08.450967Z"
        }
      },
      "source": [
        "torch.cuda.empty_cache()\n",
        "\n",
        "torch.jit.enable_onednn_fusion(True)\n",
        "if torch.cuda.is_available():\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "random.seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)"
      ],
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "id": "05238888",
      "metadata": {
        "id": "05238888"
      },
      "source": [
        "It is possible to use a cpu or gpu/s to generate inferences. Based on avaiablity of a cuda:gpu we set the device the model uses"
      ]
    },
    {
      "cell_type": "code",
      "id": "4deaa3d2",
      "metadata": {
        "id": "4deaa3d2",
        "ExecuteTime": {
          "end_time": "2024-12-12T11:06:08.496763Z",
          "start_time": "2024-12-12T11:06:08.494338Z"
        }
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')"
      ],
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "id": "89c2b66f",
      "metadata": {
        "tags": [],
        "id": "89c2b66f"
      },
      "source": [
        "### Load Config"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1aa74b62",
      "metadata": {
        "id": "1aa74b62"
      },
      "source": [
        "We provide a configuration file that is used to configure data variables and model parameters. For inference most of these configurations are used as is. This includes the variables that the model is trained on, the variables that we downscale, the number of input timesteps, the amount of downscaling, the embedding dimensions for the model. When necessary, we will show which configurations need to be specified or changed outside of what is set in this file already."
      ]
    },
    {
      "cell_type": "code",
      "id": "c8fe9d7f-ebe4-4669-ad9f-58f1a3664a3f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-09-20T18:30:35.042683Z",
          "iopub.status.busy": "2024-09-20T18:30:35.042185Z",
          "iopub.status.idle": "2024-09-20T18:30:35.145250Z",
          "shell.execute_reply": "2024-09-20T18:30:35.144820Z",
          "shell.execute_reply.started": "2024-09-20T18:30:35.042652Z"
        },
        "id": "c8fe9d7f-ebe4-4669-ad9f-58f1a3664a3f",
        "ExecuteTime": {
          "end_time": "2024-12-12T11:06:09.627774Z",
          "start_time": "2024-12-12T11:06:09.330613Z"
        }
      },
      "source": [
        "#config_path = hf_hub_download(repo_id=\"ibm-granite/granite-geospatial-wxc-downscaling\",\n",
        "#                            filename=\"config.yaml\",\n",
        "#                            local_dir=\"./\")\n",
        "config = get_config(\"config.yaml\")"
      ],
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "id": "6cd31812",
      "metadata": {
        "id": "6cd31812"
      },
      "source": [
        "### Download Model and Sample Data\n",
        "\n",
        "We provide sample data from MERRA-2 dataset for a single day (2020 January 01), and [weights](https://huggingface.co/ibm-granite/granite-geospatial-wxc-downscaling/tree/main) for a finetuned downscaling model that we use in this notebook. These will be downloaded when you run the cell/s below"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e751323",
      "metadata": {
        "id": "2e751323"
      },
      "source": [
        "Before running the download set `config.download_path` to the directory where you want the model and sample data to be downloaded\n",
        "\n",
        "*Note*: With `config.download_path = './'` the files are downloaded in the current working directory"
      ]
    },
    {
      "cell_type": "code",
      "id": "58033654",
      "metadata": {
        "id": "58033654",
        "ExecuteTime": {
          "end_time": "2024-12-12T11:06:11.345653Z",
          "start_time": "2024-12-12T11:06:11.342752Z"
        }
      },
      "source": [
        "config.download_path = './'"
      ],
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": [
        "hf_hub_download(repo_id=\"ibm-granite/granite-geospatial-wxc-downscaling\", filename=\"pytorch_model.bin\", local_dir=\"./\")\n",
        "hf_hub_download(repo_id=\"ibm-nasa-geospatial/Prithvi-WxC-1.0-2300M\", filename=\"merra-2/MERRA2_sfc_20200101.nc\", local_dir=config.download_path)\n",
        "hf_hub_download(repo_id=\"ibm-nasa-geospatial/Prithvi-WxC-1.0-2300M\", filename=\"merra-2/MERRA_pres_20200101.nc\", local_dir=config.download_path)\n",
        "hf_hub_download(repo_id=\"ibm-nasa-geospatial/Prithvi-WxC-1.0-2300M\", filename=\"climatology/anomaly_variance_surface.nc\", local_dir=config.download_path)\n",
        "hf_hub_download(repo_id=\"ibm-nasa-geospatial/Prithvi-WxC-1.0-2300M\", filename=\"climatology/anomaly_variance_vertical.nc\", local_dir=config.download_path)\n",
        "hf_hub_download(repo_id=\"ibm-nasa-geospatial/Prithvi-WxC-1.0-2300M\", filename=\"climatology/musigma_surface.nc\", local_dir=config.download_path)\n",
        "hf_hub_download(repo_id=\"ibm-nasa-geospatial/Prithvi-WxC-1.0-2300M\", filename=\"climatology/musigma_vertical.nc\", local_dir=config.download_path)\n",
        "hf_hub_download(repo_id=\"ibm-nasa-geospatial/Prithvi-WxC-1.0-2300M\", filename=\"climatology/climate_surface_doy001_hour00.nc\", local_dir=config.download_path)\n",
        "hf_hub_download(repo_id=\"ibm-nasa-geospatial/Prithvi-WxC-1.0-2300M\", filename=\"climatology/climate_surface_doy001_hour03.nc\", local_dir=config.download_path)\n",
        "hf_hub_download(repo_id=\"ibm-nasa-geospatial/Prithvi-WxC-1.0-2300M\", filename=\"climatology/climate_surface_doy001_hour06.nc\", local_dir=config.download_path)\n",
        "hf_hub_download(repo_id=\"ibm-nasa-geospatial/Prithvi-WxC-1.0-2300M\", filename=\"climatology/climate_surface_doy001_hour09.nc\", local_dir=config.download_path)\n",
        "hf_hub_download(repo_id=\"ibm-nasa-geospatial/Prithvi-WxC-1.0-2300M\", filename=\"climatology/climate_surface_doy001_hour12.nc\", local_dir=config.download_path)\n",
        "hf_hub_download(repo_id=\"ibm-nasa-geospatial/Prithvi-WxC-1.0-2300M\", filename=\"climatology/climate_surface_doy001_hour15.nc\", local_dir=config.download_path)\n",
        "hf_hub_download(repo_id=\"ibm-nasa-geospatial/Prithvi-WxC-1.0-2300M\", filename=\"climatology/climate_surface_doy001_hour18.nc\", local_dir=config.download_path)\n",
        "hf_hub_download(repo_id=\"ibm-nasa-geospatial/Prithvi-WxC-1.0-2300M\", filename=\"climatology/climate_surface_doy001_hour21.nc\", local_dir=config.download_path)\n",
        "hf_hub_download(repo_id=\"ibm-nasa-geospatial/Prithvi-WxC-1.0-2300M\", filename=\"climatology/climate_surface_doy001_hour00.nc\", local_dir=config.download_path)\n",
        "hf_hub_download(repo_id=\"ibm-nasa-geospatial/Prithvi-WxC-1.0-2300M\", filename=\"climatology/climate_vertical_doy001_hour00.nc\", local_dir=config.download_path)\n",
        "hf_hub_download(repo_id=\"ibm-nasa-geospatial/Prithvi-WxC-1.0-2300M\", filename=\"climatology/climate_vertical_doy001_hour03.nc\", local_dir=config.download_path)\n",
        "hf_hub_download(repo_id=\"ibm-nasa-geospatial/Prithvi-WxC-1.0-2300M\", filename=\"climatology/climate_vertical_doy001_hour06.nc\", local_dir=config.download_path)\n",
        "hf_hub_download(repo_id=\"ibm-nasa-geospatial/Prithvi-WxC-1.0-2300M\", filename=\"climatology/climate_vertical_doy001_hour09.nc\", local_dir=config.download_path)\n",
        "hf_hub_download(repo_id=\"ibm-nasa-geospatial/Prithvi-WxC-1.0-2300M\", filename=\"climatology/climate_vertical_doy001_hour12.nc\", local_dir=config.download_path)\n",
        "hf_hub_download(repo_id=\"ibm-nasa-geospatial/Prithvi-WxC-1.0-2300M\", filename=\"climatology/climate_vertical_doy001_hour15.nc\", local_dir=config.download_path)\n",
        "hf_hub_download(repo_id=\"ibm-nasa-geospatial/Prithvi-WxC-1.0-2300M\", filename=\"climatology/climate_vertical_doy001_hour18.nc\", local_dir=config.download_path)\n",
        "hf_hub_download(repo_id=\"ibm-nasa-geospatial/Prithvi-WxC-1.0-2300M\", filename=\"climatology/climate_vertical_doy001_hour21.nc\", local_dir=config.download_path)\n",
        "hf_hub_download(repo_id=\"ibm-nasa-geospatial/Prithvi-WxC-1.0-2300M\", filename=\"climatology/climate_vertical_doy001_hour00.nc\", local_dir=config.download_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JbpBj-8YF6KC",
        "outputId": "1863e073-b610-4ceb-ef7e-bb950288e46b"
      },
      "id": "JbpBj-8YF6KC",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'climatology/climate_vertical_doy001_hour00.nc'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "id": "ff6c50d5",
      "metadata": {
        "id": "ff6c50d5"
      },
      "source": [
        "Based on the path to the sample data downloaded in the above cells we specify the paths that are required by the dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "id": "4993928b",
      "metadata": {
        "id": "4993928b",
        "ExecuteTime": {
          "end_time": "2024-12-12T11:13:04.023234Z",
          "start_time": "2024-12-12T11:13:04.020114Z"
        }
      },
      "source": [
        "config.data.data_path_surface = os.path.join(config.download_path,'merra-2')\n",
        "config.data.data_path_vertical = os.path.join(config.download_path, 'merra-2')\n",
        "config.data.climatology_path_surface = os.path.join(config.download_path,'climatology')\n",
        "config.data.climatology_path_vertical = os.path.join(config.download_path,'climatology')\n",
        "\n",
        "config.model.input_scalers_surface_path = os.path.join(config.download_path,'climatology/musigma_surface.nc')\n",
        "config.model.input_scalers_vertical_path = os.path.join(config.download_path,'climatology/musigma_vertical.nc')\n",
        "config.model.output_scalers_surface_path = os.path.join(config.download_path,'climatology/anomaly_variance_surface.nc')\n",
        "config.model.output_scalers_vertical_path = os.path.join(config.download_path,'climatology/anomaly_variance_vertical.nc')"
      ],
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "id": "ff24860c-bc0f-4cf6-84e7-a4ac9f4221a4",
      "metadata": {
        "tags": [],
        "id": "ff24860c-bc0f-4cf6-84e7-a4ac9f4221a4"
      },
      "source": [
        "### Dataloader\n",
        "\n",
        "With the environment ready to go, we now need to set up the task. The core model expects a fixed set of variables from the MERRA-2 dataset, which are defined in the configuration file. The variables are comprised of surface variables, surface static variables, and variables at various vertical levels within the atmosphere. More details on the MERRA-2 dataset can be found [here](https://gmao.gsfc.nasa.gov/reanalysis/MERRA-2/).\n",
        "\n",
        "The task of the model is, given the input data, to increase the resolution of 2m surface temperature by 6x."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59887ecc",
      "metadata": {
        "id": "59887ecc"
      },
      "source": [
        "Set the range of the data to the sample data that we downloaded earlier"
      ]
    },
    {
      "cell_type": "code",
      "id": "61f6ae6f",
      "metadata": {
        "id": "61f6ae6f",
        "ExecuteTime": {
          "end_time": "2024-12-12T11:13:04.872470Z",
          "start_time": "2024-12-12T11:13:04.870175Z"
        }
      },
      "source": [
        "config.data.val_time_range_start = '2020-01-01T00:00:00'\n",
        "config.data.val_time_range_end = '2020-01-01T23:59:59'"
      ],
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "id": "9d8d2237",
      "metadata": {
        "id": "9d8d2237"
      },
      "source": [
        "Initialize `Merra2DownscaleDataset` class.\n",
        "\n",
        "This class is used to create samples as expected by the downscaling model. Using the transforms specified in the dataset class we coarsen and smoothen the MERRA-2 data to use as a low-resolution input to out model. The original data is used as the corresponding high-resolution data."
      ]
    },
    {
      "cell_type": "code",
      "id": "a873ef0c-7bcb-494b-9963-bd64b56f9d4d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-09-20T18:30:35.200325Z",
          "iopub.status.busy": "2024-09-20T18:30:35.200149Z",
          "iopub.status.idle": "2024-09-20T18:30:36.386899Z",
          "shell.execute_reply": "2024-09-20T18:30:36.386377Z",
          "shell.execute_reply.started": "2024-09-20T18:30:35.200310Z"
        },
        "tags": [],
        "id": "a873ef0c-7bcb-494b-9963-bd64b56f9d4d"
      },
      "source": [
        "dataset = Merra2DownscaleDataset(\n",
        "    time_range=(config.data.val_time_range_start, config.data.val_time_range_end),\n",
        "    data_path_surface = config.data.data_path_surface,\n",
        "    data_path_vertical = config.data.data_path_vertical,\n",
        "    climatology_path_surface = config.data.climatology_path_surface,\n",
        "    climatology_path_vertical = config.data.climatology_path_vertical,\n",
        "    input_surface_vars = config.data.input_surface_vars,\n",
        "    input_static_surface_vars = config.data.input_static_surface_vars,\n",
        "    input_vertical_vars = config.data.input_vertical_vars,\n",
        "    input_levels = config.data.input_levels,\n",
        "    n_input_timestamps = config.data.n_input_timestamps,\n",
        "    output_vars=config.data.output_vars,\n",
        "    transforms=_get_transforms(config),\n",
        ")\n",
        "\n",
        "assert len(dataset) > 0, \"There doesn't seem to be any valid data.\""
      ],
      "outputs": [],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "id": "4bdb5532",
      "metadata": {
        "id": "4bdb5532",
        "ExecuteTime": {
          "end_time": "2024-12-12T12:07:37.710393Z",
          "start_time": "2024-12-12T12:07:37.708272Z"
        }
      },
      "source": [
        "dataloader = DataLoader(dataset, batch_size=1)"
      ],
      "outputs": [],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "id": "eb5475fe",
      "metadata": {
        "id": "eb5475fe"
      },
      "source": [
        "### Model Init\n",
        "\n",
        "We build the model using the loaded configuration. To use the model for inference with the provided weights we will keep the model configuration the same as defined in the configuration file\n",
        "\n",
        "\n",
        "The graintewxc downscale model consists of a patch embedding layer, followed by an upscaling layer that increases the resolution by 2x, then we use the pre-trained encoder of the PrithviWxC model followed by another upscaling operation that increases the resolution by 3x for a total of 6x resolution gain"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zN4Xn0ITsVal"
      },
      "id": "zN4Xn0ITsVal",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "id": "aca0a500",
      "metadata": {
        "id": "aca0a500",
        "outputId": "d709e8dc-8c6f-4ab4-e099-89bbbc78f509",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = get_finetune_model(config, logger=None)\n",
        "model"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating the model.\n",
            "Encoder shifting: False\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ClimateDownscaleFinetuneModel(\n",
              "  (backbone): PrithviWxCEncoderDecoder(\n",
              "    (lgl_block): LocalGlobalLocalBlock(\n",
              "      (transformers): ModuleList(\n",
              "        (0-24): 25 x Transformer(\n",
              "          (drop_path): DropPath()\n",
              "          (attention): Sequential(\n",
              "            (0): LayerNormPassThrough((2560,), eps=1e-05, elementwise_affine=True)\n",
              "            (1): MultiheadAttention(\n",
              "              (qkv_layer): Linear(in_features=2560, out_features=7680, bias=False)\n",
              "              (w_layer): Linear(in_features=2560, out_features=2560, bias=False)\n",
              "            )\n",
              "          )\n",
              "          (ff): Sequential(\n",
              "            (0): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
              "            (1): Mlp(\n",
              "              (net): Sequential(\n",
              "                (0): Linear(in_features=2560, out_features=10240, bias=True)\n",
              "                (1): GELU(approximate='none')\n",
              "                (2): Dropout(p=0.0, inplace=False)\n",
              "                (3): Linear(in_features=10240, out_features=2560, bias=True)\n",
              "                (4): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (shifter): _Shift()\n",
              "    )\n",
              "  )\n",
              "  (head): ConvEncoderDecoder(\n",
              "    (blocks): ModuleList(\n",
              "      (0): PixelShuffleBlock(\n",
              "        (conv): Conv2d(2560, 1152, kernel_size=(3, 3), stride=(1, 1), padding=same, padding_mode=replicate)\n",
              "        (pixel_shuffle): PixelShuffle(upscale_factor=3)\n",
              "        (activation): PReLU(num_parameters=1)\n",
              "      )\n",
              "    )\n",
              "    (out_conv): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=same, padding_mode=replicate)\n",
              "  )\n",
              "  (embedding): PatchEmbed(\n",
              "    (proj): Conv2d(282, 256, kernel_size=(2, 2), stride=(1, 1), padding=same, padding_mode=replicate)\n",
              "  )\n",
              "  (embedding_static): PatchEmbed(\n",
              "    (proj): Conv2d(152, 256, kernel_size=(2, 2), stride=(1, 1), padding=same, padding_mode=replicate)\n",
              "  )\n",
              "  (upscale): ConvEncoderDecoder(\n",
              "    (blocks): ModuleList(\n",
              "      (0): PixelShuffleBlock(\n",
              "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=same, padding_mode=replicate)\n",
              "        (pixel_shuffle): PixelShuffle(upscale_factor=2)\n",
              "        (activation): PReLU(num_parameters=1)\n",
              "      )\n",
              "    )\n",
              "    (out_conv): Conv2d(128, 2560, kernel_size=(3, 3), stride=(1, 1), padding=same, padding_mode=replicate)\n",
              "  )\n",
              "  (conv_after_backbone): Conv2d(2560, 2560, kernel_size=(3, 3), stride=(1, 1), padding=same, padding_mode=replicate)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "execution_count": 12
    },
    {
      "cell_type": "markdown",
      "id": "bb4f2b74-f923-4bc7-81f1-9dcac83df827",
      "metadata": {
        "tags": [],
        "id": "bb4f2b74-f923-4bc7-81f1-9dcac83df827"
      },
      "source": [
        "### Load weights\n",
        "\n",
        "We can now load the weights we downloaded earlier the model that we initialized"
      ]
    },
    {
      "cell_type": "code",
      "id": "702fd455-5e7d-4779-ad7a-c3f679d7de28",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-09-20T18:32:34.583497Z",
          "iopub.status.busy": "2024-09-20T18:32:34.582963Z",
          "iopub.status.idle": "2024-09-20T18:32:59.237500Z",
          "shell.execute_reply": "2024-09-20T18:32:59.236617Z",
          "shell.execute_reply.started": "2024-09-20T18:32:34.583476Z"
        },
        "id": "702fd455-5e7d-4779-ad7a-c3f679d7de28",
        "outputId": "82ed5ffa-ba7f-4c34-cb14-0f3d10cb62d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "weights_path = Path(config.download_path,'pytorch_model.bin')\n",
        "\n",
        "\n",
        "model.load_state_dict(torch.load(weights_path, map_location=device), strict=False)\n",
        "model.to(device)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for ClimateDownscaleFinetuneModel:\n\tsize mismatch for input_scalers_mu: copying a param with shape torch.Size([1, 140, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 141, 1, 1]).\n\tsize mismatch for input_scalers_sigma: copying a param with shape torch.Size([1, 140, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 141, 1, 1]).\n\tsize mismatch for embedding.proj.weight: copying a param with shape torch.Size([256, 280, 2, 2]) from checkpoint, the shape in current model is torch.Size([256, 282, 2, 2]).\n\tsize mismatch for embedding_static.proj.weight: copying a param with shape torch.Size([256, 151, 2, 2]) from checkpoint, the shape in current model is torch.Size([256, 152, 2, 2]).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-12ebdd568487>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2583\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2584\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   2585\u001b[0m                 \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n\u001b[1;32m   2586\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ClimateDownscaleFinetuneModel:\n\tsize mismatch for input_scalers_mu: copying a param with shape torch.Size([1, 140, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 141, 1, 1]).\n\tsize mismatch for input_scalers_sigma: copying a param with shape torch.Size([1, 140, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 141, 1, 1]).\n\tsize mismatch for embedding.proj.weight: copying a param with shape torch.Size([256, 280, 2, 2]) from checkpoint, the shape in current model is torch.Size([256, 282, 2, 2]).\n\tsize mismatch for embedding_static.proj.weight: copying a param with shape torch.Size([256, 151, 2, 2]) from checkpoint, the shape in current model is torch.Size([256, 152, 2, 2])."
          ]
        }
      ],
      "execution_count": 13
    },
    {
      "cell_type": "markdown",
      "id": "9b5834fb-31df-4732-a926-bb1376b9ad42",
      "metadata": {
        "tags": [],
        "id": "9b5834fb-31df-4732-a926-bb1376b9ad42"
      },
      "source": [
        "### Inference\n",
        "\n",
        "The model is now ready for inference. We are running an inference for only one sample, but you can add a loop to run the inference for multiple samples"
      ]
    },
    {
      "cell_type": "code",
      "id": "ed0d3e93-736a-4209-b34c-f32ae1b32eaf",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-09-20T18:33:13.776977Z",
          "iopub.status.busy": "2024-09-20T18:33:13.776380Z",
          "iopub.status.idle": "2024-09-20T18:33:45.505968Z",
          "shell.execute_reply": "2024-09-20T18:33:45.505365Z",
          "shell.execute_reply.started": "2024-09-20T18:33:13.776949Z"
        },
        "tags": [],
        "id": "ed0d3e93-736a-4209-b34c-f32ae1b32eaf"
      },
      "source": [
        "import torch\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "\n",
        "    batch = next(iter(dataloader))\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "    out = model(batch)\n",
        "\n",
        "    inputs = batch['x']\n",
        "    targets = batch['y']\n",
        "    outputs = out"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8f084d8-6072-47ff-8276-e4573232044f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-09-20T18:33:45.507067Z",
          "iopub.status.busy": "2024-09-20T18:33:45.506887Z",
          "iopub.status.idle": "2024-09-20T18:33:45.568754Z",
          "shell.execute_reply": "2024-09-20T18:33:45.568317Z",
          "shell.execute_reply.started": "2024-09-20T18:33:45.507050Z"
        },
        "tags": [],
        "id": "d8f084d8-6072-47ff-8276-e4573232044f"
      },
      "outputs": [],
      "source": [
        "inputs.shape, targets.shape, outputs.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1e0a99e-3014-4f0d-b10d-b6f90572d5ab",
      "metadata": {
        "tags": [],
        "id": "f1e0a99e-3014-4f0d-b10d-b6f90572d5ab"
      },
      "source": [
        "### Plotting"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcd886d8",
      "metadata": {
        "id": "dcd886d8"
      },
      "source": [
        "We set the variable names and description and extract the sample information for generating plots"
      ]
    },
    {
      "cell_type": "code",
      "id": "394ca62c-ce10-4390-88b9-5c1df864a68c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-09-20T19:59:22.286831Z",
          "iopub.status.busy": "2024-09-20T19:59:22.286491Z",
          "iopub.status.idle": "2024-09-20T19:59:22.348934Z",
          "shell.execute_reply": "2024-09-20T19:59:22.348334Z",
          "shell.execute_reply.started": "2024-09-20T19:59:22.286808Z"
        },
        "tags": [],
        "id": "394ca62c-ce10-4390-88b9-5c1df864a68c"
      },
      "source": [
        "var_name = \"T2M\"\n",
        "var_name_title = '2M air temperature'\n",
        "var_unit = \"K\"\n",
        "\n",
        "input_vars = [*config.data.input_surface_vars, *product(config.data.input_vertical_vars, config.data.input_levels)]\n",
        "input_t2m_index= input_vars.index(var_name)\n",
        "\n",
        "sample_idx = 0\n",
        "coarsening_factor = targets.shape[-1] / inputs.shape[-1]\n",
        "sample_timestamp, sample_it, sample_lt = dataset.dataset.samples[sample_idx][0]\n",
        "sample_time_spec = SampleSpec.get(sample_timestamp, -sample_it, sample_lt)\n",
        "sample_time = sample_time_spec.inputs[-1]\n",
        "\n",
        "f'{var_name_title} at {sample_time} is downscaled by {coarsening_factor}x'"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "69a05bf4-d784-4aa6-aa7e-9e36ced47b37",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-09-20T19:38:47.091065Z",
          "iopub.status.busy": "2024-09-20T19:38:47.090817Z",
          "iopub.status.idle": "2024-09-20T19:38:47.168015Z",
          "shell.execute_reply": "2024-09-20T19:38:47.167526Z",
          "shell.execute_reply.started": "2024-09-20T19:38:47.091046Z"
        },
        "tags": [],
        "id": "69a05bf4-d784-4aa6-aa7e-9e36ced47b37",
        "ExecuteTime": {
          "end_time": "2024-12-12T12:16:10.036254Z",
          "start_time": "2024-12-12T12:16:10.033442Z"
        }
      },
      "source": [
        "plot_input = inputs[0, input_t2m_index, :, :].detach().cpu().numpy()\n",
        "plot_target = targets[0, 0, : ,:].detach().cpu().numpy()\n",
        "plot_output = outputs[0, 0, :, :].detach().cpu().numpy()\n",
        "plot_residual = plot_target - plot_output"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "1ae4ed9f-fdaa-4fbc-a515-28da25afc4f8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-09-20T20:02:06.064478Z",
          "iopub.status.busy": "2024-09-20T20:02:06.064243Z",
          "iopub.status.idle": "2024-09-20T20:02:06.533952Z",
          "shell.execute_reply": "2024-09-20T20:02:06.533392Z",
          "shell.execute_reply.started": "2024-09-20T20:02:06.064462Z"
        },
        "tags": [],
        "id": "1ae4ed9f-fdaa-4fbc-a515-28da25afc4f8",
        "ExecuteTime": {
          "end_time": "2024-12-12T12:16:11.077627Z",
          "start_time": "2024-12-12T12:16:10.703335Z"
        }
      },
      "source": [
        "plot_val_kwargs = dict(\n",
        "    cmap='RdYlBu_r',\n",
        "    vmin = min(np.min(plot_input), np.min(plot_target), np.min(plot_output)),\n",
        "    vmax = max(np.max(plot_input), np.max(plot_target), np.max(plot_output)),\n",
        "    plot_residual_kwargs = dict(\n",
        "        cmap = 'bwr',\n",
        "        vmin = -np.max(np.abs(plot_residual)),\n",
        "        vamx = np.max(np.abs(plot_residual)),\n",
        "    ),\n",
        "    var_name_title=var_name_title,\n",
        "    var_unit=var_unit\n",
        ")\n",
        "\n",
        "plot_model_results(\n",
        "    [plot_input, plot_output, plot_target],\n",
        "    ['Input', 'AI Model', 'Ground truth'],\n",
        "    title=f\"Downscaling '{var_name_title}' at {sample_time} by {coarsening_factor}x\",\n",
        "    **plot_val_kwargs\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "42774052-9f8b-4415-ac8f-207902a5ea7c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-09-20T20:03:55.224670Z",
          "iopub.status.busy": "2024-09-20T20:03:55.224359Z",
          "iopub.status.idle": "2024-09-20T20:03:56.247799Z",
          "shell.execute_reply": "2024-09-20T20:03:56.247316Z",
          "shell.execute_reply.started": "2024-09-20T20:03:55.224651Z"
        },
        "id": "42774052-9f8b-4415-ac8f-207902a5ea7c",
        "ExecuteTime": {
          "end_time": "2024-12-12T12:16:13.229972Z",
          "start_time": "2024-12-12T12:16:12.547915Z"
        }
      },
      "source": [
        "vmin_res = -np.max(np.abs(plot_residual))\n",
        "vmax_res = np.max(np.abs(plot_residual))\n",
        "pred_bias = spatial_bias(plot_output, plot_target)\n",
        "pred_rmse = spatial_rmse(plot_output, plot_target)\n",
        "\n",
        "fig, axs = plt.subplots(nrows=1,ncols=2,\n",
        "                        figsize=(15,4))\n",
        "\n",
        "title = 'Residuals - RMSE: {:.2f} K, bias: {:.2f} K'.format(pred_rmse, pred_bias)\n",
        "im_res = plot_spatial(plot_residual, axs[0], title,  **plot_val_kwargs.get('plot_residual_kwargs'))\n",
        "cbar = plt.colorbar(im_res, ax=axs[0], orientation='vertical', label=f'{var_name} [K]')\n",
        "\n",
        "plot_power_spectrum(plot_input, axs[1])\n",
        "plot_power_spectrum(plot_target, axs[1])\n",
        "plot_power_spectrum(plot_output, axs[1])\n",
        "axs[1].legend(['input', 'ground-truth', 'Prithvi WxC'])\n",
        "axs[1].set_title(f'Power spectrum of {var_name_title}')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hnNFSXnwr1fB"
      },
      "id": "hnNFSXnwr1fB",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}